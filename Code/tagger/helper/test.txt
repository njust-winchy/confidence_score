The O
paper O
proposes O
a O
new O
memory O
access O
scheme O
based O
on O
Lie O
group O
actions O
for O
NTMs O
. O

Pros O
: O
* O
Well O
written O
* O
Novel O
addressing O
scheme O
as O
an O
extension O
to O
NTM O
. O

* O
Seems O
to O
work O
slightly O
better O
than O
normal O
NTMs O
. O

* O
Some O
interesting O
theory O
about O
the O
novel O
addressing O
scheme O
based O
on O
Lie O
groups O
. O

Cons O
: O
* O
In O
the O
results O
, O
the O
LANTM O
only O
seems O
to O
be O
slightly O
better O
than O
the O
normal O
NTM O
. O

* O
The O
result O
tables O
are O
a O
bit O
confusing O
. O

* O
No O
source O
code O
available O
. O

* O
The O
difference O
to O
the O
properties O
of O
normal O
NTM O
does O
n't O
become O
too O
clear O
. O

Esp O
it O
is O
said O
that O
LANTM O
are O
better O
than O
NTM O
because O
they O
are O
differentiable O
end-to-end O
and O
provide O
a O
robust O
relative O
indexing O
scheme O
but O
NTM O
are O
also O
differentiable O
end-to-end O
and O
also O
provide O
a O
robust O
indexing O
scheme O
. O

* O
It O
is O
said O
that O
the O
head O
is O
discrete O
in O
NTM O
but O
actually O
it O
is O
in O
space O
R^n O
, O
i.e.it O
is O
already O
continuous O
. O

It O
does O
n't O
become O
clear O
what O
is O
meant O
here O
. O

* O
No O
tests O
on O
real-world O
tasks O
, O
only O
some O
toy O
tasks O
. O

* O
No O
comparisons O
to O
some O
of O
the O
other O
NTM O
extensions O
such O
as O
D-NTM O
or O
Sparse O
Access O
Memory O
( O
SAM O
) O
( O
https O
: O
//arxiv.org/abs/1610.09027 O
) O
. O

Although O
the O
motivations O
of O
other O
NTM O
extensions O
might O
be O
different O
, O
such O
comparisons O
still O
would O
have O
been O
interesting O
. O

The O
paper O
makes O
an O
interesting O
and O
timely O
contribution O
in O
investigating O
controlled O
dataset O
collection O
, O
and O
the O
impact O
of O
different O
axes O
of O
variation O
on O
object O
detection O
. O

In O
general O
, O
the O
community O
agrees O
on O
the O
importance O
of O
these O
questions O
, O
but O
there O
is O
very O
little O
work O
done O
to O
provide O
answers O
. O

As O
such O
, O
the O
originality O
and O
significance O
of O
the O
work O
is O
high O
. O

Clarity O
of O
the O
paper O
is O
also O
good O
, O
and O
release O
of O
the O
dataset O
and O
code O
should O
help O
with O
reproducibility O
. O

* O
* O
* O
Post-rebuttal O
comments O
After O
reading O
the O
other O
reviews O
and O
the O
rebuttal O
, O
I O
am O
more O
convinced O
that O
this O
paper O
should O
be O
accepted O
. O

The O
rebuttal O
addressed O
concerns O
in O
a O
thoughtful O
and O
concrete O
manner O
. O

This O
paper O
conducts O
an O
empirical O
analysis O
of O
the O
effect O
of O
training O
data O
size O
on O
the O
model O
robustness O
to O
adversarial O
examples O
. O

The O
authors O
compared O
four O
different O
NN O
architectures O
using O
four O
different O
datasets O
for O
the O
task O
of O
image O
classification O
. O

Overall O
, O
the O
paper O
is O
easy O
to O
follow O
and O
clearly O
written O
. O

However O
, O
since O
Su O
et O
al. O
, O
2018 O
, O
already O
presented O
similar O
findings O
, O
I O
do O
not O
see O
any O
major O
contribution O
in O
this O
paper O
. O

Additionally O
, O
I O
would O
expect O
the O
authors O
to O
conduct O
some O
more O
analysis O
of O
their O
results O
besides O
acc O
. O

and O
distortion O
levels O
. O

For O
examples O
, O
investigate O
the O
type O
of O
mistakes O
the O
models O
have O
made O
, O
compare O
models O
with O
the O
same O
test O
acc O
. O

but O
different O
amount O
of O
training O
data O
used O
to O
get O
there O
, O
some O
analysis/experiments O
to O
explain O
these O
findings O
( O
monitor O
models O
parameters/grads O
during O
training O
, O
etc O
. O
) O

