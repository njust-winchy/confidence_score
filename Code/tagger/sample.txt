The paper proposes a new memory access scheme based on Lie group actions for NTMs. Pros: * Well written * Novel addressing scheme as an extension to NTM. * Seems to work slightly better than normal NTMs. * Some interesting theory about the novel addressing scheme based on Lie groups. Cons: * In the results, the LANTM only seems to be slightly better than the normal NTM. * The result tables are a bit confusing. * No source code available. * The difference to the properties of normal NTM doesn't become too clear. Esp it is said that LANTM are better than NTM because they are differentiable end-to-end and provide a robust relative indexing scheme but NTM are also differentiable end-to-end and also provide a robust indexing scheme. * It is said that the head is discrete in NTM but actually it is in space R^n, i.e. it is already continuous. It doesn't become clear what is meant here. * No tests on real-world tasks, only some toy tasks. * No comparisons to some of the other NTM extensions such as D-NTM or Sparse Access Memory (SAM) (https://arxiv.org/abs/1610.09027). Although the motivations of other NTM extensions might be different, such comparisons still would have been interesting.
The paper makes an interesting and timely contribution in investigating controlled dataset collection, and the impact of different axes of variation on object detection. In general, the community agrees on the importance of these questions, but there is very little work done to provide answers. As such, the originality and significance of the work is high. Clarity of the paper is also good, and release of the dataset and code should help with reproducibility. *** Post-rebuttal comments After reading the other reviews and the rebuttal, I am more convinced that this paper should be accepted. The rebuttal addressed concerns in a thoughtful and concrete manner.
This paper conducts an empirical analysis of the effect of training data size on the model robustness to adversarial examples. The authors compared four different NN architectures using four different datasets for the task of image classification. Overall, the paper is easy to follow and clearly written. However, since Su et al., 2018, already presented similar findings, I do not see any major contribution in this paper. Additionally, I would expect the authors to conduct some more analysis of their results besides acc. and distortion levels. For examples, investigate the type of mistakes the models have made, compare models with the same test acc. but different amount of training data used to get there, some analysis/experiments to explain these findings (monitor models parameters/grads during training, etc.)